{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsuspIrInE3V"
   },
   "source": [
    "# Statistical Inference\n",
    "# IFT6758 Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwybvVZjnOtN"
   },
   "source": [
    "### Classical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGNBfVmJpNP2"
   },
   "source": [
    "2. [ISLR 3.7.3] Suppose we have a dataset with five predictors, $X_1 = $ GPA, $X_2 = IQ$, $X_3 = $ Gender (1 for Female and 0 for Male), $X_4 = $ Interaction between GPA and IQ, and $X_5 = $ Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get $\\hat{\\beta}_0 = 50, \\hat{\\beta}_1 = 20, \\hat{\\beta}_2 = 0.07, \\hat{\\beta}_3 = 35, \\hat{\\beta}_4 = 0.01, \\hat{\\beta}_5 = -10$.\n",
    "\n",
    "  a. Which is correct, and why? i. For a fixed value of IQ and GPA, males earn more on average than females. ii. For a fixed value of IQ and GPA, females earn more on average than males. iii. For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough. iv. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "    \n",
    "  b. Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "  \n",
    "  c. True or false: Since the coefficient for the GPA / IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "a) The right one is iii.) \n",
    "\n",
    "The equation for the starting salary after graduation is :\n",
    "Y = 50 + 20(GPA) + 0.07(IQ) + 35(Gender) + 0.01(GPA * IQ) -10(GPA * Gender)\n",
    "\n",
    "For male it gives us; Y = 50 + 20(GPA) + 0.07(IQ)  + 0.01(GPA * IQ)\n",
    "\n",
    "For a female it gives us ; Y = 50 + 20(GPA) + 0.07(IQ) + 35 + 0.01(GPA * IQ) -10(GPA)\n",
    "\n",
    "Given that the GPA is high enough, even if the equation for a female has the +35 due to 35(Gender), the -10(GPA) is penalizing compared to equation for a male.\n",
    "\n",
    "b) Y = 50 + 20 * 4.0 + 0.07 * 110 + 35 + 0.01(4.0 * 110) -10(4.0)\n",
    "\n",
    "   Y = 137.1\n",
    "   \n",
    "Which is 137 100$\n",
    "\n",
    "c) False, the value of the coefficient signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding the other variables in the model constant. To know whether there is an evidence of an interaction effect, we would need to know the p-value of the GPA/IQ term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhNdyJfDnrbY"
   },
   "source": [
    "### The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjXTVcT3wgdV"
   },
   "source": [
    "6. Suppose that $X_1, \\dots, X_n$ and $Y_1, \\dots, Y_m$ are two independent samples. As a measure of the difference in location of the two samples, the difference of the 20% trimmed means is used (each trimmed mean is the mean after discarding the 10% smallest and 10% largest values in the group). Explain how the bootstrap could be used to estimate the standard error of this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "What we would need to do is to :\n",
    "\n",
    "1.Sample with replacement from our independent sample X1,...,Xn\n",
    "\n",
    "2.Calculate and store the trimmed mean of our new sample\n",
    "\n",
    "3.Sample with replacement from our independent sample Y1,...,Yn\n",
    "\n",
    "3.Calculate and store the trimmed mean of our new sample\n",
    "\n",
    "4.Calculate the difference between the trimmed mean of our sample from X1,...,Xn and the trimmed mean of our sample from Y1,...,Yn and record that number\n",
    "\n",
    "5.Repeat steps 1 to 4 n times\n",
    "\n",
    "6.Calculate the standard deviation of the n recorded differences, which gives us a bootstrapped standard error of the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3F5dh3ORyt-W"
   },
   "source": [
    "7. [ISLR 4.5.9] Consider the Boston housing [dataset](https://gist.githubusercontent.com/krisrs1128/2c1ce8d004b1efc18b2d6e03e84a27c6/raw/9e95c9782b46f1ede7c288466390c8f937aecc08/boston.csv).\n",
    "\n",
    "  a. Based on this dataset, provide an estimate for the population mean of `medv`. Call this estimate $\\hat{\\mu}$.\n",
    "  \n",
    "  b. Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result. *Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.*.\n",
    "  \n",
    "  c. Now estimate the standard error $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from (b)?\n",
    "  \n",
    "  d. Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of `medv`. *Hint: You can approximate a 95% confidence interval using the formula $\\left[\\hat{\\mu} - 2 s.e.\\left(\\hat{\\mu}\\right), \\hat{\\mu} + 2 s.e.\\left(\\hat{\\mu}\\right)\\right]$.*\n",
    "  \n",
    "  e. Based on this dataset, provide an estimate $\\hat{\\mu}_{med}$ for the median value of `medv` in the population.\n",
    "  \n",
    "  f. We now would like to estimate the standard error of $\\hat{\\mu}_{med}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.\n",
    "  \n",
    "  g. Based on this dataset, provide an estimate for the 10th percentile of `medv` in Boston suburbs. Call this quantity $\\hat{\\mu}_{0.1}$.\n",
    "  \n",
    "  h. Use the bootstrap to estiamte the standard error of $\\hat{\\mu}_{0.1}$. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "22.532806324110677\n",
      "b)\n",
      "0.4084569346972866\n",
      "c)\n",
      "0.412402701271868\n",
      "The answer is similar to answer b, having a really small difference\n",
      "d)\n",
      "(21.701916929472073, 23.351527734559543)\n",
      "e)\n",
      "21.2\n",
      "f)\n",
      "0.3845271901959597\n",
      "It's a small standard error relative to the median of 21.2\n",
      "g)\n",
      "12.75\n",
      "h)\n",
      "0.4897669624423436\n",
      "It is a small standard error relative to the tenth-percentile value of 12.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "df = pd.read_csv(\"https://gist.githubusercontent.com/krisrs1128/2c1ce8d004b1efc18b2d6e03e84a27c6/raw/9e95c9782b46f1ede7c288466390c8f937aecc08/boston.csv\")\n",
    "np.random.seed(1)\n",
    "\n",
    "#a\n",
    "mu = np.mean(df[\"medv\"])\n",
    "print(\"a)\")\n",
    "print(mu)\n",
    "\n",
    "#b\n",
    "std = np.std(df[\"medv\"])\n",
    "print(\"b)\")\n",
    "print(std / np.sqrt(len(df[\"medv\"])))\n",
    "\n",
    "#c\n",
    "sample_props = []\n",
    "for i in range(1000):\n",
    "    sample = np.random.choice(df[\"medv\"], size=int(len(df[\"medv\"])), replace=True)\n",
    "    sample_props.append(sample.mean())\n",
    "    \n",
    "    \n",
    "print(\"c)\")\n",
    "print(np.std(sample_props))\n",
    "print(\"The answer is similar to answer b, having a really small difference\")\n",
    "std = np.std(sample_props)\n",
    "mu = np.mean(sample_props)\n",
    "#d\n",
    "print(\"d)\")\n",
    "print((mu - 2*std, mu + 2*std))\n",
    "\n",
    "#e\n",
    "print(\"e)\")\n",
    "print(np.median(df[\"medv\"]))\n",
    "\n",
    "#f\n",
    "sample_prop = []\n",
    "for i in range(1000):\n",
    "    samp = np.random.choice(df[\"medv\"], size=int(len(df[\"medv\"])), replace=True)\n",
    "    sample_prop.append(np.median(samp))\n",
    "\n",
    "print(\"f)\")\n",
    "print(np.std(sample_prop))\n",
    "print(\"It's a small standard error relative to the median of 21.2\")\n",
    "\n",
    "#g\n",
    "print(\"g)\")\n",
    "print(np.percentile(df[\"medv\"], 10))\n",
    "\n",
    "#h\n",
    "sample_pro = []\n",
    "for i in range(1000):\n",
    "    sam = np.random.choice(df[\"medv\"], size=int(len(df[\"medv\"])), replace=True)\n",
    "    sample_pro.append(np.percentile(sam, 10))\n",
    "print(\"h)\")\n",
    "print(np.std(sample_pro))\n",
    "print(\"It is a small standard error relative to the tenth-percentile value of 12.75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ut1P7ayknsmK"
   },
   "source": [
    "### Large-Scale Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXbEMQG8v3rI"
   },
   "source": [
    "13. The data [here](https://gist.githubusercontent.com/krisrs1128/ff7b6498c89316b9dd526a0f44d92d31/raw/2683592cd4ed08d00e17d12adbc90a6bafac434c/experiments.csv) are a simulation of 10,000 experiments, each seeking to detecting a difference between treatment and control. Only the last 10% of hypotheses are actually nonnull (ids 9001 to 10000).\n",
    "\n",
    "  a. For experiment, run a $t$-test comparing treatment and control, using an $\\alpha=0.05$ significance level. How many false positives (rejected hypotheses among the null IDs) do you find? What is the FDR in this instance (the fraction $\\frac{V}{R}$)?\n",
    "  \n",
    "  b. Apply a Bonferroni correction to all $p$-values. How many false positives do you find? What is the false discovery rate?\n",
    "  \n",
    "  c. Apply the Benjamini-Hochberg procedure. What is the false discovery rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x52ARUDUhJQ7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "df = pd.read_csv(\"https://gist.githubusercontent.com/krisrs1128/ff7b6498c89316b9dd526a0f44d92d31/raw/2683592cd4ed08d00e17d12adbc90a6bafac434c/experiments.csv\")\n",
    "    \n",
    "df_control = df[df[\"type\"]==\"control\"]\n",
    "df_treatment = df[df[\"type\"]==\"treatment\"]\n",
    "\n",
    "store_p_value = []\n",
    "for i in range(1, 10000+1):\n",
    "    array_mean_control = np.asarray(df_control[df_control[\"experiment_id\"]== i][\"value\"])\n",
    "    array_mean_treatment = np.asarray(df_treatment[df_treatment[\"experiment_id\"]== i][\"value\"])\n",
    "    p_value = ttest_ind(array_mean_control, array_mean_treatment)[1]\n",
    "    store_p_value.append(p_value)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "There are 411 false positives, denoted as V\n",
      "There are 703 rejected hypothesis\n",
      "The false discovery rate is 0.5846372688477952\n"
     ]
    }
   ],
   "source": [
    "#supposed null IDs are store_p_value[:9001]\n",
    "false_positive = 0\n",
    "for i in store_p_value[:9001]:\n",
    "    if i < 0.05:\n",
    "        false_positive +=1\n",
    "\n",
    "print(\"a)\")\n",
    "print(\"There are\",false_positive,\"false positives, denoted as V\")\n",
    "\n",
    "number_rejected = 0\n",
    "for i in store_p_value:\n",
    "    if i < 0.05:\n",
    "        number_rejected +=1\n",
    "\n",
    "print(\"There are\",number_rejected,\"rejected hypothesis\")\n",
    "print(\"The false discovery rate is\",false_positive/number_rejected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b)\n",
      "There are now 0 false positive with the bonferroni correction, the false discovery rate is 0\n"
     ]
    }
   ],
   "source": [
    "alpha_corrected = 0.05/len(store_p_value)\n",
    "false_positive_bonf = 0\n",
    "for i in store_p_value[:9001]:\n",
    "    if i < alpha_corrected:\n",
    "        false_positive_bonf +=1\n",
    "\n",
    "print(\"b)\")\n",
    "print(\"There are now\",false_positive_bonf,\"false positive with the bonferroni correction, the false discovery rate is 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c)\n",
      "There are now 0 false positive with the Benjamini-Hochberg procedure, the FDR is 0\n"
     ]
    }
   ],
   "source": [
    "asc_p_value = sorted(store_p_value)\n",
    "\n",
    "new_alpha = 0\n",
    "for idx, value in enumerate(asc_p_value):\n",
    "    if value < (0.05*idx+1) / len(store_p_value):\n",
    "        new_alpha = value\n",
    "\n",
    "f_positive = 0\n",
    "for i in store_p_value[:9001]:\n",
    "    if i < new_alpha:\n",
    "        f_positive +=1\n",
    "\n",
    "print(\"c)\")\n",
    "truc= 0\n",
    "for i in store_p_value:\n",
    "    if i < new_alpha:\n",
    "        truc +=1\n",
    "        \n",
    "        \n",
    "print(\"There are now\",f_positive,\"false positive with the Benjamini-Hochberg procedure, the FDR is\",f_positive) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "problem_sheet_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
