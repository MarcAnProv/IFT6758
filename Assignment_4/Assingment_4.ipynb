{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Z6yb_gzz1XI"
   },
   "source": [
    "# Assignmnet 4\n",
    "\n",
    "### IFT6758 Fall 2019\n",
    "\n",
    "### Due date: December 15, 2019\n",
    "\n",
    "### Submit your answers and code as a pdf file in gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W97qSa5O_SxR"
   },
   "source": [
    "## Marc-Antoine Provost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzOxCc2oz1XK"
   },
   "source": [
    "### Deep Learning (Convolutional Neural Networks) [60 points + 10 bonus points]\n",
    "\n",
    "This set of assignments will give you experience with deep learning. You will learn how to use convolution neural networks on a image corpus. \n",
    "\n",
    "For this problem use [documentation for Keras](https://keras.io/) deep learning library and for [Sklearn](https://scikit-learn.org/stable/index.html). Provide your code and the output.\n",
    "\n",
    "#### Data preparation (20 points)\n",
    "\n",
    "1. (1 point) Search MNIST dataset at [OpenML](https://www.openml.org/), it is called \"mnist_784\". Download it using sklearn function `fetch_openml`. Get features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN00q8BjoE9-"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRSF6Kdbz1XL"
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "mnist_data = fetch_openml('mnist_784')\n",
    "X, y = mnist_data['data'], mnist_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avYhvNxUv5pl"
   },
   "outputs": [],
   "source": [
    "# reshape\n",
    "x_reshaped = np.reshape(X, (X.shape[0],28,28))\n",
    "\n",
    "def show_images(images, labels=None, columns=5, show_num=5):\n",
    "  for i in range(show_num):\n",
    "    plt.subplot(show_num / columns + 1, columns, i + 1)\n",
    "\n",
    "    if labels is not None:\n",
    "      plt.title(labels[i])\n",
    "\n",
    "    plt.grid(None)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "IUqddXfP1WBZ",
    "outputId": "0a255e29-5a4b-4019-e024-e8c5bbce7ece"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABYCAYAAABWMiSwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAOVklEQVR4nO3deZDdU/rH8fcjGUIyQWKnbJHwQxFL\nFiZFrFHWRKy/iLVQSCgjyliLsQumLEGGISHqR4rYKz+UWCOUfcqW2IqyDEkQEhKDM3/cfvr0vb2k\nM933nO/t/ryqUuncvt399Dfd5z7f55zzHAshICIiaSyXOwARkc5Eg66ISEIadEVEEtKgKyKSkAZd\nEZGENOiKiCSkQVdEJKHCDLpm9oyZLTazhXV/ZueOKTcz62VmD5jZIjP71Mz+N3dMRWFmfet+Xqbk\njiU3MxtjZq+a2RIzm5Q7nqIws/8xsxlmtsDMPjSzEbljggINunXGhBB61P3ZNHcwBTAB+AVYExgF\n3GxmW+QNqTAmAK/kDqIgvgQuAW7PHUhRmFlX4CHgUaAXcAIwxcz6ZQ2M4g26UsfMugMjgfNDCAtD\nCC8ADwOj80aWn5kdBnwPPJU7liIIIUwLITwIzM8dS4FsBqwD/C2E8FsIYQYwkwL8/hRt0L3czOaZ\n2UwzG5o7mMz6Ab+GEOY0eOwtoFNnumbWE/gr8OfcsUjNMWDL3EEUadA9C9gYWBf4O/CImfXJG1JW\nPYAfKh5bAPwxQyxFcjHwjxDC57kDkUKbDXwDnGlmfzCzPYGdgZXyhlWgQTeE8HII4ccQwpIQwmRK\ntwJ7544ro4VAz4rHegI/ZoilEMysP7A78LfcsUixhRD+DQwH9gH+BZwBTAWyv1h3zR1ACwKl24HO\nag7Q1cz6hhA+qHtsa+CdjDHlNhTYEPjMzKB0N9DFzDYPIWybMS4poBDCPylltwCY2YvA5HwRlRQi\n0zWzVcxsmJl1M7OuZjYK2An4/9yx5RJCWARMA/5qZt3N7E/AAcBdeSPL6u9AH6B/3Z9bgMeAYTmD\nyq3ud6Yb0IXSi1C3utn7Ts3Mtqq7FiuZ2ThgbWBS5rCKMegCf6C05GUuMA8YCwyvmETqjE4GVqRU\nm/o/4KQQQqfNdEMIP4UQ/uV/KJVgFocQ5uaOLbPzgJ+BvwBH1L19XtaIimE08BWl35/dgD1CCEvy\nhgSmJuYiIukUJdMVEekUNOiKiCSkQVdEJCENuiIiCWnQFRFJqMW1fGbWKZY2hBBavQlD16Rpui6N\n6Zo0pmuiTFdEJCkNuiIiCWnQFRFJSIOuiEhCGnRFRBLSoCsikpAGXRGRhDp9z81ast122wEwZswY\nAI488kgA7rzzTgBuuOEGAF5//fUM0YlIayjTFRFJqMV+uil2j3Tp0gWAlVdeucn3e1a30kql8+Q2\n3XRTAE455RQArr76agAOP/zw+o9ZvHgxAFdccQUAF110UYsxFH1HTf/+/QGYMWMGAD17Vh6dVrJg\nwQIAevfu3eav2RF3pO22224A3H333fWP7bxz6TSX2bNnt+pzFP1nZWnOO6/U29x/J5ZbrpR3DR06\ntP45zz777DJ9zlq/JtWgHWkiIgVR9Zru+uuvD8Dyyy8PwI477gjAkCFDAFhllVUAGDlyZKs+3+ef\nlw7zvP766wEYMWIEAD/+GA/Jfeutt4Blf8UumoEDBwJw//33A/FuwO9O/Hv+5ZdfgJjhDh48GCiv\n7fpzctlpp52AGOMDDzyQPIYBAwYA8MorryT/2rkdffTRAJx11lkA/P7772Xv1wky6SjTFRFJqCqZ\nrtcgIdYhm6vZtpa/MntNauHChUCsz3311Vf1z/3uu++A1tfpisLr1ttuWzpNfMqUKQCsvfbaTT7/\ngw9KJ7NfddVVANxzzz0AzJw5E4jXCuDyyy+vQsSt5zXDvn37AmkzXa9bbrTRRgBssMEG9e+rO8q9\nw/PvuVu3bpkjqb5BgwYBcMQRRwCxbr/FFluUPW/cuHEAfPnll0C8+/bfu5dffrkq8SnTFRFJSIOu\niEhCVSkvfPbZZ/Vvz58/H2h9ecFT+u+//x6AXXbZBYgTQXfddVe7xVk0EydOBMqXv7XEyxA9evQA\n4sSh38pvtdVW7Rzhf883csyaNSv51/byzPHHHw/E20eA999/P3k8Ke2+++4AjB07tuxx/7733Xdf\nAL7++uu0gVXBoYceCsB1110HwGqrrQbEEtIzzzwDwOqrrw7A+PHjyz7en+fvP+yww6oSpzJdEZGE\nqpLpfvvtt/Vvn3nmmUB8RX3jjTeAuOTLvfnmmwDsscceACxatAiIxe/TTjutGqEWgm/v3WeffYDG\nkzuewT7yyCNA3BDiEwB+TX0Ccdddd23y8+Tkk1k53HbbbWX/9gnIjswnhe644w6g8Z2mZ3mffvpp\n2sDaUdeupeFr++23B+DWW28F4oT0c889B8DFF18MwAsvvADACiusAMDUqVMB2HPPPcs+76uvvlrN\nsJXpioikVPXNEQ8++CAQl475gv6tt94agOOOOw6I2ZtnuO6dd94B4IQTTqh2qMn50ronn3wSiNt7\nfaH69OnTgVjj9aUvvhTMM7i5c+cCcVOIL6/zzBli/Td1MxyvK6+55ppJv25DlVmeX++O7KijjgJg\nnXXWKXvc65reJKmW+ZKwyjsZ///1Gu8PP/xQ9n5/vDLD9Y1XkydPbv9gG1CmKyKSULLWjpWvNt6c\nxfnM8r333gs03qbYkfTr1w+I9W7PxObNmwfEjR7+iusbQR577LGyv5dmxRVXrH/7jDPOAGDUqFFt\nin1Z7b333o1iScWza98U4b744ovksaTiM/bHHnssEH+PfDXQJZdckiewduQ12nPOOQeId4Y33XQT\nEO8EK8ccd+655zb5+KmnngrEO8dqUaYrIpJQtibmF154IRBn7r1e6esKn3jiiSxxVYvPmEKsX3sW\n6HVuX8vqs6ftmR1646HUvBWn8xp9Cn6dPeOdM2cOUN4cqaPYcMMNgdgcqZI3uH/66adThdSuLrjg\ngvq3PcP1tfuPP/44EJv5/Pzzz2Uf61ufvYbrvwu+usez/4ceeqgqsVdSpisiklC2TNdXKXgt12fV\nfa2dvyJ71jdhwgSgdlvQbbPNNvVve4brDjjgAKD2W1G2RjXaKvqqj7322guIs9qVs9NeC/T6Zkfi\n33vlLsSnnnoKiLu0ao23fj355JPrH/MxwDPc4cOHN/mxm2yyCRCbYvldtbvvvvuA2DAqFWW6IiIJ\nZT+Y8qOPPgJik2XfQTN69Oiyv7t37w7E9YUNWznWgmuvvbb+ba8leWbb3hmu7/4q4gqQXr16LfU5\nvobbr5PX+ddbbz0gNsT3lRj+/Xotz/t3LFmyBIg7l1577bW2fwMF41meH03lfPeVr9etXC1UK/z/\n2ldlNOSrDdZYYw0AjjnmGAD2339/ALbccksg9ibxDNn/9h4clXsDqk2ZrohIQtkzXedNrX1fvGeG\nfpjgZZddBsRmzJdeeilQ/DWX3nOiYWN3f6V9+OGHq/I1PcNtWP/23hapefbpsdxyyy1AnIFuitcl\nPdP99ddfAfjpp58AePfddwG4/fbbgVj39zsG75jlO4x8FUhH6ii2tNUKH3/8MVD73cN8hULDtbPe\nBeyTTz4Bmp/n8d4kvl7Xu835enjvZZKaMl0RkYQKk+m6t99+G4BDDjkEgP322w+Itd4TTzwRiMe+\neFeyovIsy2tTAN988w0Qd9+1la8B9rXPzvtdAJx99tnt8rWWlc86ezcrP5i0Jd6P2ft2vPfeewC8\n9NJLrfqa3qfDMyLP+jqS5g6YdJU13lrlK00arlB49NFHgTg/4PNCvs520qRJQOx26MdYeabr/85F\nma6ISEKFy3Sdv8L5SRHeSchnov1Ibz8lwbsn1QKfVW/rCgzPcH2vufdy8FrmNddcU/9c79+Qy5VX\nXpnsa/k8gGuu7lmLfG6gcg2y82yv1g5lXZqGh0T6HczS+Bjhu139riD3nY8yXRGRhAqX6frM9UEH\nHQTAgAEDgJjhOp/B9u7wtaStqxY82/HM1vuDepYzcuTINn3+jiblce/V5j1JVl111bLHvd7t690l\nzqdUruZRTVdEpBPJnul6F6oxY8YAcOCBBwKw1lprNfn83377DYj10CLuumrI15o2PK/MZ2KX9dy3\n008/HYDzzz8fiH14fW+5dymTjqt3795A45977yWbu3ZfJN6boWiU6YqIJJQ80/UM1s/98gzXd9g0\nx3cd+U60au3mam+V+70hXgM/Edl3Vs2fPx+AwYMHA7HvhPci8N4Dvo7VX8k9y5FyfnfhJ3W0dp1v\nEfk69eZOVX7xxRdThlMThg0bljuEJinTFRFJqOqZrnft33zzzQG48cYbAdhss81a/Dhflzd+/Hgg\nzswXvYbbGl26dAHibi1fbeB7xH23XSXPZrzXcMNu+tKY3100lx3WAl+p4p3W/OffexJ4n+la77FQ\nDRtvvHHuEJpUuz+NIiI1SIOuiEhC7Vpe8AYUEydOrH/Mb4+Wlur7rbNvXfVJospD5mrNrFmzgPJj\nanzDh/OJNS/FOJ9Y88Xcy7rETEp22GEHIDZCqSV+XE3lEkpvaTpu3LjkMdWK559/HiheU39luiIi\nCbUp0x00aBAQt6MOHDgQgHXXXXepH+sNqX3ZlDcpT310RrV58xnf9AGxPaU3qqnkhwjefPPNAHz4\n4YfVDLHDarghRTofbxPrByP43XafPn2A8sboKSnTFRFJqE2Z7ogRI8r+boo3pvHGw370itduO+Jx\n2E1p2MbRm41XNh2X9jF9+nQADj744MyRtJ0fMeRzHkOGDMkZTk3yu2hvD+sbrMaOHQvEMSoVZboi\nIglZc4e6AZhZ8+/sQEIIrS7+6Zo0TdelMV2TxnJck549ewIwdepUIG40mTZtGhCPbm/P+aSWroky\nXRGRhJTpUvxX6hyU6TZNPyuN1co18YzXa7onnXQSEA9OaM/arjJdEZGCUKZL7bxSp6RMt2n6WWlM\n16QxZboiIgXRYqYrIiLtS5muiEhCGnRFRBLSoCsikpAGXRGRhDToiogkpEFXRCSh/wB7OhUrZO3U\noQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(x_reshaped, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "___LmoL7z1XN"
   },
   "source": [
    "> This dataset represents each (28x28) image as a flat arrray of 784 features.\n",
    "\n",
    "2. (3 point) Reshape it back to 28x28 and visualize a couple of images with matplotlib.\n",
    "\n",
    "> Finally, we want to add one dummy dimension for the non-existent color information. Every resulting image should have dimensions 28x28x1. \n",
    ">\n",
    "> We want this extra dimensions because image libraries are targeted towards RGB images that have 3 channels. Therefore RGB images are conviniently represented by the shape of WxHx3. We don't have 3 colors for MNIST dataset, so we just provide 1 channel.\n",
    "\n",
    "3. (3 point) Add a channel dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Im01is2z1XN",
    "outputId": "c8c5ff20-aee5-4558-c43f-0a5e439645c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution here\n",
    "x_reshaped = x_reshaped[:,:,:, np.newaxis]\n",
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fn9MhHtSz1XP"
   },
   "source": [
    "> To simplify the task we exclude some classes.\n",
    "\n",
    "4. (3 point) Filter data leaving only classes `1`, `3`, `7`. Transform features and targets. How many data points left after filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ktKgguIQz1XP",
    "outputId": "47ffe4e0-e3ac-4fe0-a797-06f551553a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 22311 data points left after filtering.\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "# find indices where the label is not 1, 3, or 7\n",
    "wanted_classes = ['1','3','7']\n",
    "indices = [i for i in range(len(y)) if y[i] not in wanted_classes]\n",
    "\n",
    "x_filtered = np.delete(x_reshaped, indices, axis=0)\n",
    "y_filtered = np.delete(y, indices, axis=0).astype(int)\n",
    "print(f\"There are now {len(x_reshaped) - len(indices)} data points left after filtering.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5V6yFByz1XR"
   },
   "source": [
    "5. (5 point) Convert targets to one-hot representation. Complete the following template.\n",
    "\n",
    "\n",
    "```python\n",
    "def to_categorical(array, classes):\n",
    "    \"\"\"\n",
    "    array -- array of targets\n",
    "    classes -- list of classes\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "mnist_targets = to_categorical(mnist_targets, classes=...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wcXJ9pRz1XS"
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def to_categorial(target, classes):\n",
    "  one_hot = [[] for i in range(len(target))]\n",
    "  for idx, value in enumerate(target):\n",
    "    one_hot[idx] = np.zeros(len(classes), dtype=int).tolist()\n",
    "    for i, number in enumerate(classes):\n",
    "      if value == number:\n",
    "        one_hot[idx][i] += 1\n",
    "  return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZ1vtzbChtdF"
   },
   "outputs": [],
   "source": [
    "mnist_targets = to_categorial(y_filtered, np.unique(y_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFSmQf2az1XT"
   },
   "source": [
    "6. (5 point) Split the dataset into train, validataion, and test. Take first 16,000 images and targets as the train, then next 3,000 as validation, then the rest as the test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOshw8xxz1XU"
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "x_train = x_filtered[:16000]\n",
    "y_train = mnist_targets[:16000]\n",
    "x_valid = x_filtered[16000:19000]\n",
    "y_valid = mnist_targets[16000:19000]\n",
    "x_test = x_filtered[19000:]\n",
    "y_test = mnist_targets[19000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqrBeME2V-ir"
   },
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train, (16000,3))\n",
    "y_valid = np.reshape(y_valid, (3000,3))\n",
    "y_test = np.reshape(y_test, (3311,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbd6JDHFz1XW"
   },
   "source": [
    "\n",
    "#### Training (35 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLwaDGjhz1XW"
   },
   "source": [
    "Use Keras (https://keras.io/) to create a neural network model. Use a sequential layer to combine following layers in this order:\n",
    "- Convolution with 6 feature maps 5x5\n",
    "- Rectified linear unit activation\n",
    "- Max-pooling by factor of 2 each spacial dimension\n",
    "- Convolution with 16 feature maps 5x5\n",
    "- Rectified linear unit activation\n",
    "- Max-pooling by factor of 2 each spacial dimension\n",
    "- Flatten layer\n",
    "- Dense layer with 128 output units\n",
    "- Rectified linear unit activation\n",
    "- Dense layer. Same size as the target.\n",
    "- Softmax activation\n",
    "\n",
    "1. (10 points) Complete the following template.\n",
    "\n",
    "```python\n",
    "... # place your imports here\n",
    "\n",
    "model = Sequential([\n",
    "    ..., # convolution\n",
    "    ..., # activation\n",
    "    ..., # pooling\n",
    "    ..., # convolution\n",
    "    ..., # activation\n",
    "    ..., # pooling\n",
    "    Flatten(),\n",
    "    ..., # fully connected\n",
    "    ..., # activation\n",
    "    ..., # fully connected output\n",
    "    ..., # softmax\n",
    "])\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "id": "EvRbp25Uz1XX",
    "outputId": "9ac003f3-aa7c-44c3-c400-c30e67a4b681"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 35,855\n",
      "Trainable params: 35,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size = 5, activation = 'relu', input_shape = input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, kernel_size= 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5mn_1G-z1XZ"
   },
   "source": [
    "2. (5 point) Create a stochastic gradient optimizer optimizer with learning rate of $10^{-4}$. Compile the model with the categorical crossentropy loss. Set the model to report accuracy metric. Complete the template.\n",
    "\n",
    "\n",
    "```python\n",
    "... # place your imports here\n",
    "\n",
    "optimizer = ... # create stochastic gradient optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9hX9AsDfz1XZ",
    "outputId": "29286c51-195c-48a8-c7f9-5637eeb58a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "from keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(lr=1e-4)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['accuracy'],\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4CJxXqVz1Xb"
   },
   "source": [
    "3. (15 points) Train the model on the training set for at least 5 epochs. Perform validation after every epoch.\n",
    "\n",
    "> **HINT** Find a method that performs training in the Keras documentation. Study the documentation paying attention to all arguments and the return value of the method.\n",
    "\n",
    "> The model should have at least 95% accuracy on the training set. It might happen that the training gets stuck. In this case, go to the step before prevoious, recreate and rerun the model. \n",
    "\n",
    "> **WARNING** This step might take several minutes to compute on a laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "aIBpRiD0z1Xb",
    "outputId": "73e0f839-42c5-440b-dfbe-1be138793b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 16000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "16000/16000 [==============================] - 9s 535us/step - loss: 1.9452 - acc: 0.8393 - val_loss: 0.2541 - val_acc: 0.9637\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 8s 517us/step - loss: 0.2300 - acc: 0.9660 - val_loss: 0.1764 - val_acc: 0.9760\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 8s 529us/step - loss: 0.1758 - acc: 0.9730 - val_loss: 0.1329 - val_acc: 0.9797\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 8s 524us/step - loss: 0.1441 - acc: 0.9773 - val_loss: 0.1190 - val_acc: 0.9790\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 8s 514us/step - loss: 0.1240 - acc: 0.9789 - val_loss: 0.1032 - val_acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc0ad89240>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution here\n",
    "model.fit(x_train, y_train, batch_size = 32, verbose=1, epochs=5, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJZUHX0dz1Xd"
   },
   "source": [
    "4. (5 point) Plot the training loss against the validation loss. Do you observe overfitting/underfitting?\n",
    "\n",
    "> **HINT** Explore the return value in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "E02CbYsBz1Xd",
    "outputId": "1f94410e-4cb9-4af6-c268-62bfd93c8660"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhcd33v8fd3RiPJkrzItrxKlk3I\n4iWOF8WWSUOSJgQnkH1xQqwSLpCGQnNpe7kNXNpQSu/lufBQLm2gGEgBJ3ESHBIMJIQACSHFm2wc\nx0sWx/Eied9t7cv3/jFH8lgeySNboyNpPq/nOc/MnN/vzHw19uijc35nfsfcHRERkY4iYRcgIiJ9\nkwJCRESSUkCIiEhSCggREUlKASEiIkkpIEREJCkFhEgPMLMfmtlXUuy7zcyuOdfnEUk3BYSIiCSl\ngBARkaQUEJIxgkM7nzOz9WZWY2Y/MLPRZva8mR03s9+YWWFC/xvNbKOZHTGzl81sckLbTDNbG2z3\nJJDb4bU+bGbrgm3/aGbTz7LmT5rZFjM7ZGbLzGxcsN7M7F/NbJ+ZHTOz181sWtB2vZltCmqrNrP/\ncVZvmGQ8BYRkmtuADwAXADcAzwNfAIqIfx4eADCzC4AlwGeDtueAn5tZtpllA88Ci4HhwE+C5yXY\ndibwCPCXwAjgu8AyM8vpTqFm9ufA/wHuBMYC24EnguZrgfcHP8fQoM/BoO0HwF+6+2BgGvC77ryu\nSBsFhGSaf3P3ve5eDfwBWOnuf3L3euAZYGbQbwHwS3d/0d2bgK8Dg4D3AeVADPimuze5+1JgdcJr\n3Ad8191XunuLu/8IaAi26457gEfcfa27NwCfB+aZ2USgCRgMXASYu292993Bdk3AFDMb4u6H3X1t\nN19XBFBASObZm3C/LsnjguD+OOJ/sQPg7q3ATmB80Fbtp850uT3hfinwd8HhpSNmdgQoCbbrjo41\nnCC+lzDe3X8H/DvwMLDPzBaZ2ZCg623A9cB2M/u9mc3r5uuKAAoIkc7sIv6LHogf8yf+S74a2A2M\nD9a1mZBwfyfwL+4+LGHJc/cl51hDPvFDVtUA7v4td58NTCF+qOlzwfrV7n4TMIr4obCnuvm6IoAC\nQqQzTwEfMrOrzSwG/B3xw0R/BJYDzcADZhYzs1uBOQnbfg+438zmBoPJ+Wb2ITMb3M0algAfM7MZ\nwfjF/yZ+SGybmV0aPH8MqAHqgdZgjOQeMxsaHBo7BrSew/sgGUwBIZKEu78JLAT+DThAfED7Bndv\ndPdG4FbgXuAQ8fGKnyZsWwl8kvghoMPAlqBvd2v4DfAPwNPE91rOA+4KmocQD6LDxA9DHQS+FrRV\nANvM7BhwP/GxDJFuM10wSEREktEehIiIJKWAEBGRpBQQIiKSlAJCRESSygq7gJ40cuRInzhxYthl\niIj0G2vWrDng7kXJ2tIWEGZWAvwYGA04sMjd/1+HPgb8P+Lf+qwF7m2bFsDMPgp8Mej6lWC6gi5N\nnDiRysrKnvshREQGODPb3llbOvcgmoG/c/e1wReE1pjZi+6+KaHPdcD5wTIX+A4w18yGAw8BZcTD\nZY2ZLXP3w2msV0REEqRtDMLdd7ftDbj7cWAz8XlsEt0E/NjjVgDDzGws8EHgRXc/FITCi8D8dNUq\nIiKn65VB6mD2yZnAyg5N44nPW9OmKljX2fpkz32fmVWaWeX+/ft7qmQRkYyX9kFqMysgPlXAZ939\nWE8/v7svAhYBlJWV6WvhIgNEU1MTVVVV1NfXh13KgJCbm0txcTGxWCzlbdIaEMFEYk8Dj7n7T5N0\nqSY+Q2ab4mBdNXBlh/Uvp6dKEemLqqqqGDx4MBMnTuTUiXOlu9ydgwcPUlVVxaRJk1LeLm2HmIIz\nlH4AbHb3b3TSbRnwF8GMl+XA0eCiJy8A15pZYXAJyGuDdSKSIerr6xkxYoTCoQeYGSNGjOj23lg6\n9yAuIz6r5Otmti5Y9wWCefPd/T+IX8bxeuKzXdYCHwvaDpnZP3PyKl1fdvdDaaxVRPoghUPPOZv3\nMm0B4e6vAl1WFFyR69OdtD1C/Lq+aVXf1MLi5duZNn4o884bke6XExHpNzJ+qo1oxPjeH7ay6JV3\nwi5FRPqQI0eO8O1vf7vb211//fUcOXIkDRX1vowPiFg0wt1zJvDyW/vZcbA27HJEpI/oLCCam5u7\n3O65555j2LBh6SqrV2V8QADcPWcCETMeW9XpN85FJMM8+OCDvPPOO8yYMYNLL72Uyy+/nBtvvJEp\nU6YAcPPNNzN79mymTp3KokWL2rebOHEiBw4cYNu2bUyePJlPfvKTTJ06lWuvvZa6urqwfpyzMqAm\n6ztbY4bm8oHJo3lq9U7+5poLyI1Fwy5JRBL80883smlXz36Nasq4ITx0w9RO27/61a+yYcMG1q1b\nx8svv8yHPvQhNmzY0H6a6COPPMLw4cOpq6vj0ksv5bbbbmPEiFPHMd9++22WLFnC9773Pe68806e\nfvppFi5c2KM/RzppDyJQMa+Uw7VNPPf67rBLEZE+aM6cOad8h+Bb3/oWl1xyCeXl5ezcuZO33377\ntG0mTZrEjBkzAJg9ezbbtm3rrXJ7hPYgAu87bwTvKcrn0RXbuXVWcdjliEiCrv7S7y35+fnt919+\n+WV+85vfsHz5cvLy8rjyyiuTfscgJyen/X40Gu13h5i0BxEwMxbOLWXtjiNsqD4adjkiErLBgwdz\n/PjxpG1Hjx6lsLCQvLw83njjDVasWNHL1fUOBUSC22YXkxuL8NhKDVaLZLoRI0Zw2WWXMW3aND73\nuc+d0jZ//nyam5uZPHkyDz74IOXl5SFVmV4W/67awFBWVubnesGgv1+6nmWv7WLFF65m6KDUJ7US\nkZ61efNmJk+eHHYZA0qy99TM1rh7WbL+2oPooGJeKXVNLfx0bVXYpYiIhEoB0cG08UOZUTKMR1ds\nZyDtXYmIdJcCIomK8lLe2V/D8q0Hwy5FRCQ0CogkPjR9LMPyYjy6QoPVIpK5FBBJ5Mai3FlWwgsb\n97L3mK5mJSKZSQHRiXvmTqCl1VmyakfYpYiIhEIB0YnSEflccUERS1btoKmlNexyRKSPKygoAGDX\nrl3cfvvtSftceeWVnOlU/G9+85vU1p6cWTrM6cMVEF2oKC9l77EGfrNpb9iliEg/MW7cOJYuXXrW\n23cMiDCnD1dAdOGqi0YxftggHtU3q0UyzoMPPsjDDz/c/vhLX/oSX/nKV7j66quZNWsWF198MT/7\n2c9O227btm1MmzYNgLq6Ou666y4mT57MLbfccspcTJ/61KcoKytj6tSpPPTQQ0B8AsBdu3Zx1VVX\ncdVVVwEnpw8H+MY3vsG0adOYNm0a3/zmN9tfL13Tiqdtsj4zewT4MLDP3aclaf8ccE9CHZOBouB6\n1NuA40AL0NzZt/zSLRoxPjJ3Al974U227DvBe0cVhFGGiDz/IOx5vWefc8zFcN1XO21esGABn/3s\nZ/n0p+NXRX7qqad44YUXeOCBBxgyZAgHDhygvLycG2+8sdPrPX/nO98hLy+PzZs3s379embNmtXe\n9i//8i8MHz6clpYWrr76atavX88DDzzAN77xDV566SVGjhx5ynOtWbOG//zP/2TlypW4O3PnzuWK\nK66gsLAwbdOKp3MP4ofA/M4a3f1r7j7D3WcAnwd+7+6HErpcFbSHEg5tFlxaQixqmp9JJMPMnDmT\nffv2sWvXLl577TUKCwsZM2YMX/jCF5g+fTrXXHMN1dXV7N3b+SHoV155pf0X9fTp05k+fXp721NP\nPcWsWbOYOXMmGzduZNOmTV3W8+qrr3LLLbeQn59PQUEBt956K3/4wx+A9E0rnrY9CHd/xcwmptj9\nbmBJumo5FyMLcrhu2liWrqnicx+8kLxszZAu0uu6+Es/ne644w6WLl3Knj17WLBgAY899hj79+9n\nzZo1xGIxJk6cmHSa7zN59913+frXv87q1aspLCzk3nvvPavnaZOuacVDH4MwszziexpPJ6x24Ndm\ntsbM7jvD9veZWaWZVe7fvz8tNVbMK+V4fTPL1u1Ky/OLSN+0YMECnnjiCZYuXcodd9zB0aNHGTVq\nFLFYjJdeeont27s+svD+97+fxx9/HIANGzawfv16AI4dO0Z+fj5Dhw5l7969PP/88+3bdDbN+OWX\nX86zzz5LbW0tNTU1PPPMM1x++eU9+NOeri/8OXwD8F8dDi/9mbtXm9ko4EUze8PdX0m2sbsvAhZB\nfDbXdBRYVlrIRWMGs3jFdhZcWtLp8UYRGVimTp3K8ePHGT9+PGPHjuWee+7hhhtu4OKLL6asrIyL\nLrqoy+0/9alP8bGPfYzJkyczefJkZs+eDcAll1zCzJkzueiiiygpKeGyyy5r3+a+++5j/vz5jBs3\njpdeeql9/axZs7j33nuZM2cOAJ/4xCeYOXNmWq9Sl9bpvoNDTL9INkid0OcZ4Cfu/ngn7V8CTrj7\n18/0ej0x3XdnHl2xnS8+u4Fn/up9zJxQmJbXEJGTNN13z+tX032b2VDgCuBnCevyzWxw233gWmBD\nOBWedPPM8RTkZLFY8zOJSIZIW0CY2RJgOXChmVWZ2cfN7H4zuz+h2y3Ar929JmHdaOBVM3sNWAX8\n0t1/la46U1WQk8UtM8fzi/W7OVTTGHY5IiJpl86zmO5Ooc8PiZ8Om7huK3BJeqo6NwvLS1m8Yjs/\nqdzJX15xXtjliAx47q4xvx5yNsMJoZ/F1J9cOGYwcyYN57GVO2ht1cWERNIpNzeXgwcP6sJdPcDd\nOXjwILm5ud3ari+cxdSvVJSX8tdL/sQrb+/nygtHhV2OyIBVXFxMVVUV6Tp9PdPk5uZSXFzcrW0U\nEN30waljGFmQw6MrtisgRNIoFosxadKksMvIaDrE1E3ZWRHunlPCb9/Yx85DtWfeQESkn1JAnIW7\n50zAQBcTEpEBTQFxFsYNG8TVk0fz5OqdNDS3hF2OiEhaKCDOUkV5KQdrGvnVhj1hlyIikhYKiLP0\nZ+8dycQReTyqb1aLyAClgDhLkYixsLyU1dsOs3n3sbDLERHpcQqIc3D77GJysiLaixCRAUkBcQ6G\n5WVzwyXjeOZP1Ryvbwq7HBGRHqWAOEcV5aXUNrbwzJ+qwy5FRKRHKSDO0SUlw5hePJTFy7drzhgR\nGVAUED1gYXkpb+87wap3D525s4hIP6GA6AE3TB/H0EExXUxIRAYUBUQPGJQd5fbZxfxqwx72Ha8P\nuxwRkR6hgOgh98ydQHOr8+SqnWGXIiLSIxQQPeQ9RQVcfv5IHl+1g+aW1rDLERE5Z+m8JvUjZrbP\nzDZ00n6lmR01s3XB8o8JbfPN7E0z22JmD6arxp62sLyU3Ufr+e0b+8IuRUTknKVzD+KHwPwz9PmD\nu88Ili8DmFkUeBi4DpgC3G1mU9JYZ4+5+qJRjB2aq29Wi8iAkLaAcPdXgLM573MOsMXdt7p7I/AE\ncFOPFpcmWdEIH5kzgT+8fYB3D9SEXY6IyDkJewxinpm9ZmbPm9nUYN14IHGktypYl5SZ3WdmlWZW\n2ReuXbtgTglZEeMx7UWISD8XZkCsBUrd/RLg34Bnz+ZJ3H2Ru5e5e1lRUVGPFng2Rg3O5YPTxvCT\nNVXUNepiQiLSf4UWEO5+zN1PBPefA2JmNhKoBkoSuhYH6/qNivJSjtY18fP1u8IuRUTkrIUWEGY2\nxswsuD8nqOUgsBo438wmmVk2cBewLKw6z8bcScM5f1SBBqtFpF9L52muS4DlwIVmVmVmHzez+83s\n/qDL7cAGM3sN+BZwl8c1A58BXgA2A0+5+8Z01ZkOZkbFvFLWVx3ltZ1Hwi5HROSs2ECagbSsrMwr\nKyvDLgOA4/VNzP3fv+VDF4/la3dcEnY5IiJJmdkady9L1hb2WUwD1uDcGDfPHM+y13ZxpLYx7HJE\nRLpNAZFGC+eW0tDcytI1VWGXIiLSbQqINJoybghlpYU8umI7ra0D51CeiGQGBUSaVcwrZdvBWl7d\nciDsUkREukUBkWbzp41hRH62TnkVkX5HAZFmOVlRFlxawm8272XXkbqwyxERSZkCohfcPWcCDixZ\ntSPsUkREUqaA6AUlw/P48wtHsWTVThqbdTEhEekfFBC9ZOG8Ug6caOCFjXvCLkVEJCUKiF5yxflF\nlAwfxGINVotIP6GA6CWRiLFwbimr3j3EW3uPh12OiMgZKSB60R1lJWRnRXTKq4j0CwqIXjQ8P5sP\nXzyWn66t5kRDc9jliIh0SQHRyxbOK+VEQzPP/qlfXQNJRDKQAqKXzSwZxtRxQ3h0xXYG0lTrIjLw\nKCB6mZlRUV7KG3uOU7n9cNjliIh0SgERghtnjGNwbpYGq0WkT1NAhCAvO4vbZhXz3Ou7OXCiIexy\nRESSSuc1qR8xs31mtqGT9nvMbL2ZvW5mfzSzSxLatgXr15lZ37iGaA9bWF5KU4vz5OqdYZciIpJU\nOvcgfgjM76L9XeAKd78Y+GdgUYf2q9x9RmfXSu3v3juqgPedN4LHV+6gRRcTEpE+KG0B4e6vAIe6\naP+ju7eN0q4AitNVS19VUV5K9ZE6XnpjX9iliIicpq+MQXwceD7hsQO/NrM1ZnZfVxua2X1mVmlm\nlfv3709rkT3tmimjGT0kR/MziUifFHpAmNlVxAPi7xNW/5m7zwKuAz5tZu/vbHt3X+TuZe5eVlRU\nlOZqe1YsGuHuORN45e39bD9YE3Y5IiKnCDUgzGw68H3gJnc/2Lbe3auD233AM8CccCpMv7sunUDE\njMdX6mJCItK3hBYQZjYB+ClQ4e5vJazPN7PBbfeBa4GkZ0INBGOG5nLtlNE8WbmT+qaWsMsREWmX\nztNclwDLgQvNrMrMPm5m95vZ/UGXfwRGAN/ucDrraOBVM3sNWAX80t1/la46+4KK8lKO1Dbxy/W7\nwy5FRKRdVrqe2N3vPkP7J4BPJFm/Fbjk9C0GrnnnjeA9RfksXrGd22Zn3MlcItJHhT5ILSfnZ1q3\n8wgbqo+GXY6ICKCA6DNunVXMoFhU8zOJSJ+hgOgjhg6KcdOMcTy7rpqjdU1hlyMiooDoSxaWl1Lf\n1MrTa6rCLkVERAHRl0wbP5SZE4bpYkIi0icoIPqYivJSth6o4Y/vHDxzZxGRNFJA9DHXXzyWwryY\nBqtFJHQKiD4mNxblzktL+PWmvew5Wh92OSKSwRQQfdA9c0ppdWfJKs3PJCLhUUD0QRNG5HHFBUUs\nWbWDppbWsMsRkQylgOijKspL2Xe8gRc37Q27FBHJUAqIPurKC0cxftggFi/XYLWIhCOlgDCz/25m\nQyzuB2a21syuTXdxmSwaMe4pn8DyrQfZsu942OWISAZKdQ/iv7n7MeLXZigEKoCvpq0qAeDOshKy\noxEeXaHBahHpfakGhAW31wOL3X1jwjpJk5EFOVx38RieXlNFbWNz2OWISIZJNSDWmNmviQfEC8EV\n33R6TS+oKC/leEMzP1u3K+xSRCTDpBoQHwceBC5191ogBnwsbVVJu9mlhVw0ZjCLl2t+JhHpXakG\nxDzgTXc/YmYLgS8CurJNLzAzKuaVsmn3MdbuOBJ2OSKSQVINiO8AtWZ2CfB3wDvAj8+0kZk9Ymb7\nzGxDJ+1mZt8ysy1mtt7MZiW0fdTM3g6Wj6ZY54B084zxFORk8ZjmZxKRXpRqQDR7/PjGTcC/u/vD\nwOAUtvshML+L9uuA84PlPuJBhJkNBx4C5gJzgIfMrDDFWgec/Jwsbps1nl+s382hmsawyxGRDJFq\nQBw3s88TP731l2YWIT4O0SV3fwU41EWXm4Afe9wKYJiZjQU+CLzo7ofc/TDwIl0HzYB3T3kpjS2t\nPFW5M+xSRCRDpBoQC4AG4t+H2AMUA1/rgdcfDyT+xqsK1nW2/jRmdp+ZVZpZ5f79+3ugpL7pgtGD\nmTtpOI+t3E5LqwarRST9UgqIIBQeA4aa2YeBenc/4xhEb3D3Re5e5u5lRUVFYZeTVhXzStl5qI5X\n3hq4QSgifUeqU23cCawC7gDuBFaa2e098PrVQEnC4+JgXWfrM9q1U8ZQNDiHxRqsFpFekOohpv9F\n/DsQH3X3vyA+cPwPPfD6y4C/CM5mKgeOuvtu4AXgWjMrDAanrw3WZbTsrAh3X1rCS2/uY+eh2rDL\nEZEBLtWAiLj7voTHB1PZ1syWAMuBC82sysw+bmb3m9n9QZfngK3AFuB7wF8BuPsh4J+B1cHy5WBd\nxrtrzgQMeFwXExKRNMtKsd+vzOwFYEnweAHxX+5dcve7z9DuwKc7aXsEeCTF+jLGuGGDuGbyaJ5c\nvZPPXnM+OVnRsEsSkQEq1UHqzwGLgOnBssjd/z6dhUnnKuaVcqimkedf3xN2KSIygKW6B4G7Pw08\nncZaJEWXnTeSSSPzWbxiOzfPTHr2r4jIOetyD8LMjpvZsSTLcTM71ltFyqkiEeOeuRNYs/0wm3bp\nn0FE0qPLgHD3we4+JMky2N2H9FaRcro7ZpeQG4vw6Eqd8ioi6aFrUvdTQ/Ni3DB9HM/+qZpj9U1h\nlyMiA5ACoh+rmFdKbWMLz6zN+O8QikgaKCD6senFw7ikeCiLV+hiQiLS8xQQ/dzC8lK27DvBiq36\nHqGI9CwFRD93wyXjGDooxqOan0lEepgCop/LjUW5s6yYFzbuYd+x+rDLEZEBRAExAHxkbinNrc4T\nq3UxIRHpOQqIAWDSyHwuP38kj6/cQXNLa9jliMgAoYAYICrKS9lzrJ7fbN535s4iIilQQAwQf37R\nKMYNzdVgtYj0GAXEAJEVjfCRuRN4dcsBtu4/EXY5IjIAKCAGkDsvLSEWNR5bqYsJici5U0AMIKMG\n5/LBqWP4SeVO6hpbwi5HRPq5tAaEmc03szfNbIuZPZik/V/NbF2wvGVmRxLaWhLalqWzzoGkoryU\nY/XN/Py1XWGXIiL9XMoXDOouM4sCDwMfAKqA1Wa2zN03tfVx979J6P/XwMyEp6hz9xnpqm+gmjNp\nOBeMLuDHK7ZxR1kxZhZ2SSLST6VzD2IOsMXdt7p7I/AEcFMX/e/m5DWv5SyZGRXlpWyoPsZrVUfD\nLkdE+rF0BsR4IPGrvVXButOYWSkwCfhdwupcM6s0sxVmdnP6yhx4bp45nvzsKIuX65RXETl7fWWQ\n+i5gqbsnjqyWunsZ8BHgm2Z2XrINzey+IEgq9+/f3xu19nmDc2PcMms8v1i/i8M1jWGXIyL9VDoD\nohooSXhcHKxL5i46HF5y9+rgdivwMqeOTyT2W+TuZe5eVlRUdK41DxgLy0tpaG5l6ZqqsEsRkX4q\nnQGxGjjfzCaZWTbxEDjtbCQzuwgoBJYnrCs0s5zg/kjgMmBTx22lcxeNGcKlEwt5dOV2Wlt1MSER\n6b60BYS7NwOfAV4ANgNPuftGM/uymd2Y0PUu4Ak/9ZJok4FKM3sNeAn4auLZT5KaheWlbD9Yyx+2\nHAi7FBHph9J2miuAuz8HPNdh3T92ePylJNv9Ebg4nbVlgvnTxjCyIJvFy7dzxQU6/CYi3dNXBqkl\nDXKyoiy4tITfvbGX6iN1YZcjIv2MAmKAu3vOBBxYovmZRKSbFBADXHFhHldfNIonVu+gsVkXExKR\n1CkgMsDC8lIOnGjkVxv3hF2KiPQjCogM8P7zi5gwPI9H9c1qEekGBUQGiESMheUTWLXtEG/sORZ2\nOSLSTyggMsQds0vIzorokqQikjIFRIYozM/mw9PH8szaak40NIddjoj0AwqIDFJRXkpNYwvP/Kmz\nKbFERE5SQGSQGSXDmDZ+CI8u386pM5uIiJxOAZFB2i4m9Obe46zedjjsckSkj1NAZJgbLxnP4Nws\nFmuwWkTOQAGRYQZlR7ljdgm/2rCb/ccbwi5HRPowBUQGuqd8Ak0tzlOVO8/cWUQylgIiA51XVMBl\n7x3BYyu206KLCYlIJxQQGaqivJRdR+v53Rv7wi5FRPooBUSGumbyaEYPydFgtYh0SgGRobKiET4y\np5RX3trPtgM1YZcjIn1QWgPCzOab2ZtmtsXMHkzSfq+Z7TezdcHyiYS2j5rZ28Hy0XTWmanumlNC\nVsR4fJUuJiQip0tbQJhZFHgYuA6YAtxtZlOSdH3S3WcEy/eDbYcDDwFzgTnAQ2ZWmK5aM9XoIblc\nO3U0T1XupL6pJexyRKSPSecexBxgi7tvdfdG4AngphS3/SDworsfcvfDwIvA/DTVmdEWlpdypLaJ\nX6zfHXYpItLHpDMgxgOJJ9pXBes6us3M1pvZUjMr6ea2mNl9ZlZpZpX79+/vibozyrz3jOC8onwN\nVovIacIepP45MNHdpxPfS/hRd5/A3Re5e5m7lxUVFfV4gQNd2/xMr+08wvqqI2GXIyJ9SDoDohoo\nSXhcHKxr5+4H3b1tvofvA7NT3VZ6zq2zixkUi+piQiJyinQGxGrgfDObZGbZwF3AssQOZjY24eGN\nwObg/gvAtWZWGAxOXxuskzQYkhvj5pnjWfbaLo7WNoVdjoj0EWkLCHdvBj5D/Bf7ZuApd99oZl82\nsxuDbg+Y2UYzew14ALg32PYQ8M/EQ2Y18OVgnaTJwvIJ1De1snRtVdiliEgfYQPpwjFlZWVeWVkZ\ndhn91q3f/i8O1zbx27+9gkjEwi5HRHqBma1x97JkbWEPUksfUjGvlHcP1PDHdw6GXYqI9AEKCGl3\n3bSxDM/PZvGKbWGXIiJ9gAJC2uXGotxZVsKLm/ay+2hd2OWISMgUEHKKe+ZOwIElq3QxIZFMp4CQ\nU5QMz+PKC4pYsmoHTS2tYZcjIiFSQMhpKuaVsv94A7/euDfsUkQkRAoIOc0VF4yiuHCQBqtFMpwC\nQk4TjRj3zC1lxdZDvL33eNjliEhIFBCS1J1lxWRHI5qfSSSDKSAkqREFOVx/8Rh+uraamobmsMsR\nkRAoIKRTFfNKOd7QzM/W7Qq7FBEJgQJCOjVrQiGTxw7hx8u3MZDm7BKR1CggpFNtFxN6Y89x1u44\nHHY5ItLLFBDSpZtmjGNwThaLl2uwWiTTKCCkS/k5Wdw2u5jnXt/DwRMNZ95ARAYMBYSc0T1zJ9DY\n0spTlbqYkEgmUUDIGZ0/ejDl7xnOYyu309KqwWqRTKGAkJRUlE+k6nAdv39rX9iliEgvSWtAmNl8\nM3vTzLaY2YNJ2v/WzDaZ2d5zJykAAA9PSURBVHoz+62ZlSa0tZjZumBZls465cyunTqaosE5GqwW\nySBpCwgziwIPA9cBU4C7zWxKh25/AsrcfTqwFPi/CW117j4jWG5MV50ANBwHneffpVg0wt1zJvDy\nW/vZcbA27HJEpBdkpfG55wBb3H0rgJk9AdwEbGrr4O4vJfRfASxMYz2d+8YUaG2BIeOCZXyS++Mh\nbziYhVJiX3D3nBIefmkLj63azuevmxx2OSKSZukMiPFA4mXJqoC5XfT/OPB8wuNcM6sEmoGvuvuz\nyTYys/uA+wAmTJjQ/SpbW+GK/wnHdsGx6vjtu7+H47vBO1wwJyu3iwBpC5GREBmYQztjhw7imsmj\n+EllFX9zzQXkxqJhlyQiaZTOgEiZmS0EyoArElaXunu1mb0H+J2Zve7u73Tc1t0XAYsAysrKun+c\nKBKB9/316etbmqFm36nB0X67C3Ysh2O7obWpw/PFYMjYDsFRfGqYFIyCSP/85VpRPpEXNu7l//7q\nTeZMKmRYXjbD87MpzMtmWF6MWHRghqNIJkpnQFQDJQmPi4N1pzCza4D/BVzh7u3fxHL36uB2q5m9\nDMwETguItIlmnfwFT1nyPq2tULP/1OBIvF+9Fjb/Alo6fMHMojB4bNeHtAaPgWgs7T9md73vvBFM\nGTuER/7rXR75r3dPax+cm0VhXjaF+dkU5sUYnnC/MAiSeHu8bVheNtlZChWRvsjSNQmbmWUBbwFX\nEw+G1cBH3H1jQp+ZxAen57v72wnrC4Fad28ws5HAcuAmd99EF8rKyryysrLnf5hz4Q61h5LvhRyr\nOnm/qePAr0HBaBg6/vSxkLYwGTwWsnJ6/UdqamnlwIkGDtc0cbi2kUM1jRypbeRQ8Di+NHG45mRb\nTWNLp89XkJNFYX7sZHgEYTI8L5thwW1iwAzLi+nwlkgPMbM17p70r+C07UG4e7OZfQZ4AYgCj7j7\nRjP7MlDp7suArwEFwE8sPvi7IzhjaTLwXTNrJX6m1VfPFA59lhnkj4gvY6cn7+MO9UeS7IUEtwfe\nhq2/h4Zjp2+bX9T1wPqQcRAb1KM/UiwaYezQQYwdmvrzNjS3cKS2iUM1QYDUNHGotpEjNY3x26Dt\nSG0jWw+c4EhNE8e7uA5Ffna0/fDWsLxY+2GuwrxshufHkrYpVES6J217EGHok3sQPan+WHzw/Fg1\nHE22R1IdD5qOBg3vemB9yDjIKej9n+cMGptbORLsjbTvpSSEyeEgbA7VNgV7MI0cr+88VAbFoqeE\nxrC8bIbnnQyT9kNhwWGx4XnZDMpWqMjAFsoehKRB7pD4UnRh530aa+KD50kPaVVD9RqoPXD6djlD\nE0IjCI6Oh7dyhvTqab7ZWRFGDcll1JDclLdpamnlSG1wqKvm5OGuZIfBdh6q5XBtE0frmjp9vpys\nyMm9k8TDYG1jLB3GVQrzssnLjmIZfDq0DBwKiIEmOx9Gvje+dKapHo7vSj6wfqwa9m6AE/uADnuX\n2QUnAyRvJOQODUJr6MklJ+F+W1tWbq8FSywaoWhwDkWDUx+baW5p5Whd0ylhEg+X04Nm065jHKpt\n5GhdU6ffrczOirTvibQFyJBBWQyKZZGfE2VQdpT87CwGZUfJS7jffpsTJS+WRV5OVGeFSagUEJko\nlgvD3xNfOtPcCCf2JA+Qo9VwZAfUH40vrWe4ZnU0O773kZskPDoLlfa2IfFgSuN3S7KiEUYU5DCi\nIPVQaWn1k6FSc3JQ/nBwGCxx3eY9xzhR30xtYwu1jc10Z77DWNQYFIuSn9MhRLKj5GVnkReETF5O\nFnmxIHxy2tYntHe4nxuLaC9HzkgBIcllZcOwCfGlK+7QVHcyLOqPxgfT64/Gx0PqjyVZfzQYLwke\nN9d1/RoWCQKmLTyGnSFwkoRMtGf/q0cjxvD8+B4CRalv5+40NLdS29hCTUMzdU0t8eBoiAdITWMz\ndY0t1DS2UNfYHNzGg6Xtfk1DMwdrGtlxqDahbwuNLa1nLiBgBnmxIFhOC5BT93Da24IQiu8FZZGf\nHQ36nHo/GlHwDBQKCDk3ZpCdF1+GjD2752huTC1U6o+ebDu87WRbsrO7Osou6EaoDImHUGJbLPVx\nkK6YGbmxKLnBgHlPamqJB09dYtA0NFPb1EJtQzxk6ppaqGk4GT5tezVttycamtl/vCFh+xbqmjo/\nRTmZnKxIfI8nIUySBctpe0M58UAaFIuvz45GyIlF4rdZEbKzIuRkRcnOiiiEeokCQsKXlQ1ZIyF/\n5Nlt39oSn3Ax6V7M0Q6BE9ye2AMH3jzZ5mf4JRjNOfOeSse9lsTAieWnfQqWWDTC0EERhg7q2S9Y\ntrb6yT2d9jA5NVjie0Fd99l9tOnkuoYWaptazvr6ItGItYdGdrQtPCJkBwGS0/b4lLa2/tH24Dml\nb2IIRRMfJ/aLnvaaWQN4nEgBIf1fJAqDhsWXs+EeP/sraagc6Txwjuw8ub65/syvY5H4VCzRGESy\ngttY/PBX+/qOj8+lX/Y5PMfJx5FIjPxoFvnZMRgUg8igHgk7d6expbU9LBIPszU0tdLQ3EpDcwuN\nza00trTS0BS/bWyOLx3bGjq01TQ0c7il7XFiW2v7dj0hYrSHRk4s2mGPJ3nwnBJYQVtngZYslDq2\nt+219TQFhIhZ/HsgOcFZWmejqT4Ii4RgSQyVpjpoaYrP3dXSHNwme9x86vrm+vjeUWf9WhpP3abj\nBJPp0mnYdRY+p4eRRWPkRGLkRLMo7Ngvmp3wfEHQ5caSr492XJ8btAXPE80Oasw+uY1Ze0Alhsep\nAdKSJHja7recFloNHcKnoanlZFtTK8fqmk9ra0h43nMxIj+bNf/wgR76xz1JASHSE2K58aVgVLh1\ntLamGD5Jwqi723UMpzM9R2Nt6q/V0shpp1n3pEgWFs0OAip2hkBJYX1WFuR0o38k65Qg80iMJovR\nRBZNHqXBozR6lIbW+P361iiNLZwePEHAZEXTMyajgBAZSCIRiOSEMkdXj2ttiQdFS1NCICXcP219\nh3XtAXSO65sb44cg29c3xkOtpTEhJIP7Z7kHZ0B2sHTeKZokbIK9roLRMPf5rrY+KwoIEembItH4\neEcPzyWWVq0tHfauGrsZcme5Pjs/LT+OAkJEpKdEovGlh06LDtvAPT9LRETOiQJCRESSUkCIiEhS\nCggREUlKASEiIkkpIEREJCkFhIiIJKWAEBGRpMw7u25iP2Rm+4HtZ7n5SCDJxZpDp7q6R3V1j+rq\nnoFYV6m7J73s1YAKiHNhZpXuXhZ2HR2pru5RXd2juron0+rSISYREUlKASEiIkkpIE5aFHYBnVBd\n3aO6ukd1dU9G1aUxCBERSUp7ECIikpQCQkREksq4gDCz+Wb2ppltMbMHk7TnmNmTQftKM5vYR+q6\n18z2m9m6YPlEL9T0iJntM7MNnbSbmX0rqHm9mc1Kd00p1nWlmR1NeK/+sZfqKjGzl8xsk5ltNLP/\nnqRPr79nKdbV6++ZmeWa2Sozey2o65+S9On1z2OKdfX65zHhtaNm9icz+0WStp59v9w9YxYgCrwD\nvIf45V9fA6Z06PNXwH8E9+8Cnuwjdd0L/Hsvv1/vB2YBGzppvx54nvgldcuBlX2kriuBX4Tw/2ss\nMCu4Pxh4K8m/Y6+/ZynW1evvWfAeFAT3Y8BKoLxDnzA+j6nU1eufx4TX/lvg8WT/Xj39fmXaHsQc\nYIu7b3X3RuAJ4KYOfW4CfhTcXwpcbWbWB+rqde7+CnCoiy43AT/2uBXAMDMb2wfqCoW773b3tcH9\n48BmYHyHbr3+nqVYV68L3oMTwcNYsHQ8a6bXP48p1hUKMysGPgR8v5MuPfp+ZVpAjAd2Jjyu4vQP\nSnsfd28GjgIj+kBdALcFhyWWmllJmmtKRap1h2FecIjgeTOb2tsvHuzazyT+12eiUN+zLuqCEN6z\n4HDJOmAf8KK7d/p+9eLnMZW6IJzP4zeB/wm0dtLeo+9XpgVEf/ZzYKK7Twde5ORfCXK6tcTnl7kE\n+Dfg2d58cTMrAJ4GPuvux3rztbtyhrpCec/cvcXdZwDFwBwzm9Ybr3smKdTV659HM/swsM/d16T7\ntdpkWkBUA4lJXxysS9rHzLKAocDBsOty94Pu3hA8/D4wO801pSKV97PXufuxtkME7v4cEDOzkb3x\n2mYWI/5L+DF3/2mSLqG8Z2eqK8z3LHjNI8BLwPwOTWF8Hs9YV0ifx8uAG81sG/HD0H9uZo926NOj\n71emBcRq4Hwzm2Rm2cQHcZZ16LMM+Ghw/3bgdx6M+IRZV4fj1DcSP44ctmXAXwRn5pQDR919d9hF\nmdmYtuOuZjaH+P/ztP9SCV7zB8Bmd/9GJ916/T1Lpa4w3jMzKzKzYcH9QcAHgDc6dOv1z2MqdYXx\neXT3z7t7sbtPJP474nfuvrBDtx59v7LOdsP+yN2bzewzwAvEzxx6xN03mtmXgUp3X0b8g7TYzLYQ\nHwi9q4/U9YCZ3Qg0B3Xdm+66zGwJ8bNbRppZFfAQ8QE73P0/gOeIn5WzBagFPpbumlKs63bgU2bW\nDNQBd/VCyEP8L7wK4PXg+DXAF4AJCbWF8Z6lUlcY79lY4EdmFiUeSE+5+y/C/jymWFevfx47k873\nS1NtiIhIUpl2iElERFKkgBARkaQUECIikpQCQkREklJAiIhIUgoIkT7A4rOpnjY7p0iYFBAiIpKU\nAkKkG8xsYXCtgHVm9t1gUrcTZvavwbUDfmtmRUHfGWa2IpjQ7RkzKwzWv9fMfhNMjLfWzM4Lnr4g\nmPjtDTN7rBdmERbpkgJCJEVmNhlYAFwWTOTWAtwD5BP/JutU4PfEv9kN8GPg74MJ3V5PWP8Y8HAw\nMd77gLapNmYCnwWmEL82yGVp/6FEupBRU22InKOriU/Ktjr4434Q8emgW4Engz6PAj81s6HAMHf/\nfbD+R8BPzGwwMN7dnwFw93qA4PlWuXtV8HgdMBF4Nf0/lkhyCgiR1BnwI3f//Ckrzf6hQ7+znb+m\nIeF+C/p8Ssh0iEkkdb8FbjezUQBmNtzMSol/jm4P+nwEeNXdjwKHzezyYH0F8Pvgim5VZnZz8Bw5\nZpbXqz+FSIr0F4pIitx9k5l9Efi1mUWAJuDTQA3xi8p8kfghpwXBJh8F/iMIgK2cnLm1AvhuMAtn\nE3BHL/4YIinTbK4i58jMTrh7Qdh1iPQ0HWISEZGktAchIiJJaQ9CRESSUkCIiEhSCggREUlKASEi\nIkkpIEREJKn/D0jA4nWYV8a6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your solution here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title(\"model loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zYecXWyPduU"
   },
   "source": [
    "I do not observe overfitting since the validation loss doesn't increase, but continues to decrease as the number of epochs grow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRqIv9xZz1Xf"
   },
   "source": [
    "#### Evaluation (5 points)\n",
    "\n",
    "1. (1 point) Make prediciton of the model on the test set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmv0rOkyz1Xg"
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "test_predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKNg0W0Bz1Xh"
   },
   "source": [
    "2. (4 points) Compute the confusion matrix and the accuracy. Which classes confused most often?\n",
    "\n",
    "> The model should have at least 90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ySchYxb0wgT"
   },
   "outputs": [],
   "source": [
    "y_pred = list(np.argmax(test_predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xr9y8D59z1Xi"
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_filtered[19000:]\n",
    "y_confusion = np.zeros(len(y_true))\n",
    "\n",
    "for idx, val in enumerate(y_pred):\n",
    "  if val == 0:\n",
    "    y_confusion[idx] += 1\n",
    "  elif val == 1:\n",
    "    y_confusion[idx] += 3\n",
    "  elif val == 2:\n",
    "    y_confusion[idx] += 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "6fejpGZP8rxe",
    "outputId": "5c4ef9fe-bb55-45b6-c514-5a0424046b23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1173</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1019</td>\n",
       "      <td>21</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>1043</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1206</td>\n",
       "      <td>1040</td>\n",
       "      <td>1065</td>\n",
       "      <td>3311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   1.0   3.0   7.0   All\n",
       "True                             \n",
       "1          1173     8     1  1182\n",
       "3            13  1019    21  1053\n",
       "7            20    13  1043  1076\n",
       "All        1206  1040  1065  3311"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_true, y_confusion)\n",
    "pd.crosstab(y_true, y_confusion, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYqsr3FvPqdd"
   },
   "source": [
    "The classes that are confused most often are the class 3 and 7, with 34 uncorrect predictions for class 3 and 33 uncorrect preditions for class 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_RXshgLz1Xk"
   },
   "source": [
    "#### Bonus point (10 points)\n",
    "\n",
    "Can you suggest/implement a new model/paramter to omprove the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "f6CRTjSpEA3h",
    "outputId": "2b78c9ec-3af6-4fbe-cb1e-cfec8a34930d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 16000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 56s 3ms/step - loss: 0.8786 - acc: 0.9386 - val_loss: 0.1748 - val_acc: 0.9880\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 55s 3ms/step - loss: 0.2432 - acc: 0.9813 - val_loss: 0.1035 - val_acc: 0.9910\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 54s 3ms/step - loss: 0.1258 - acc: 0.9886 - val_loss: 0.0775 - val_acc: 0.9927\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 54s 3ms/step - loss: 0.0949 - acc: 0.9911 - val_loss: 0.0409 - val_acc: 0.9950\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 55s 3ms/step - loss: 0.0761 - acc: 0.9909 - val_loss: 0.0324 - val_acc: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbc55c2780>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgK_1_SSF7Tf"
   },
   "source": [
    "With dropout and another optimizer, I was able to achieve 99.6% accuracy on the validation set, which is an improvement from the previous CNN implemented (1% improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSPkmqIZz1Xk"
   },
   "source": [
    "### Graph ML [40 points]\n",
    "\n",
    "This set of assingments will teach you the differences between various node embeddings in graphs. Note that all questions are programming assingments but you do not need to use loss function to optimize the claculation of thesee embeddings.\n",
    "\n",
    "1- (5 points) Write a function randadjmat(n,p) in Python which returns an adjacency matrix for a \"random graph\" on n vertices. Here p is the probability of having an edge between any pair of vertices.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeQCdczuz1Xl"
   },
   "outputs": [],
   "source": [
    "def randadjmat(n,p):\n",
    "    #your solution here\n",
    "    adjacency = np.random.random((n,n))\n",
    "    adjacency = np.where(adjacency < p, 1,0)\n",
    "    np.fill_diagonal(adjacency, 0)\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yx5xxqfdz1Xn"
   },
   "source": [
    "2- (5 points) Write a function transionmat(A) which, given an adjacency matrix A, generate a transition matrix T where probability of each edge (u,v) is calculated as $1/degree(u)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDwHKejWz1Xn"
   },
   "outputs": [],
   "source": [
    "def transionmat(A):\n",
    "    #your solution here\n",
    "    T = A.astype(float)\n",
    "    for i in range(A.shape[0]):\n",
    "      degree = np.sum(T[i])\n",
    "      T[i] = np.dot(T[i], 1/degree)\n",
    "    return T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iwkaLWyz1Xp"
   },
   "source": [
    "3- (5 points) Write a function hotembd(A) which, given an adjacency matrix A, generate an embedding matrix H where each node is represetned with a 1-hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GK5qonBUz1Xq"
   },
   "outputs": [],
   "source": [
    "def hotembd(A):\n",
    "    #your solution here\n",
    "    n = len(A)\n",
    "    H = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "      H[i][i] += 1\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wj327X0Fz1Xr"
   },
   "source": [
    "4- (5 points) Write a function randwalkemb(A,k) which, given an adjacency matrix A, a transition matrix T, and one-hot encoding H, performs [random walks](https://en.wikipedia.org/wiki/Random_walk) on the graph from each node w times with lenght equal to l and generate an embedding matrix for each node based on the sum of 1-hot encodings of all nodes that are visited during the walks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sclvC0kj_OCr"
   },
   "outputs": [],
   "source": [
    "def randwalkembd(A,T, H, w, l):\n",
    "  n = len(A)\n",
    "  embedding_matrix = np.zeros((n,n)) \n",
    "  for node in range(n):\n",
    "    node_embedding = np.zeros((n,)) \n",
    "    for walk in range(w):\n",
    "      nodes_visited = np.zeros((n,)) \n",
    "      nodes_visited += H[node] \n",
    "      for step in range(l):\n",
    "        current_node = np.random.choice(n, size=1, p=T[node])[0]\n",
    "        nodes_visited += H[current_node]\n",
    "      node_embedding += nodes_visited\n",
    "    embedding_matrix[node] = node_embedding\n",
    "  return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LmVTdbbz1Xu"
   },
   "source": [
    "5- (5 points) Write a function hopeneighbormbd(A,H, k) which, given an adjacency matrix A, and one-hot node encoding matrix H, generates node embedding matrix which represents each node as sum of 1-hot encodings of k-hobs neighbors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d78ER544z1Xv"
   },
   "outputs": [],
   "source": [
    "def hopeneighbormbd(A, H, k):\n",
    "    #your solution here\n",
    "    from numpy.linalg import matrix_power\n",
    "    n = len(A)\n",
    "    K_hop_matrix = np.zeros((n,n))\n",
    "    K_hop_matrix = matrix_power(A, k)\n",
    "    return K_hop_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTI-7W7mz1Xz"
   },
   "source": [
    "6- (5 points) Write a function similarnodes(Z) which, given an node embedding matrix, find the most similar nodes in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gu4IdRM-z1Xz"
   },
   "outputs": [],
   "source": [
    "def similarnodes(Z):\n",
    "    #your solution here\n",
    "    import heapq\n",
    "    n = len(Z)\n",
    "    computed = [0 for i in range(n)]\n",
    "    results = [0 for i in range(n)]\n",
    "    for node in range(n):\n",
    "      for node2 in range(n):\n",
    "        if node2 == node:\n",
    "          continue\n",
    "        cosine_similarity = dot(Z[node], Z[node2])/ (norm(Z[node])*norm(Z[node2]))\n",
    "        computed[node2] = (cosine_similarity)\n",
    "      results[node] = max(computed)\n",
    "    most_similar = np.argpartition(results, -2)[-2:]\n",
    "    return print(f\"The most similar nodes are node {most_similar[0]} and node {most_similar[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxScaoM6z1X1"
   },
   "source": [
    "7- (10 points) generate a random graph where n=20, and p=0.6, and compare the most similar nodes in the graph using randwalkembd (l=4, w=10), hopeneighbormbd (k=1) and hopeneighbormbd (k=2). Justify why similar nodes are different using different node embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "x8FN7oCuHYjo",
    "outputId": "c182f402-b8b4-4316-e1c6-b0250b349d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar nodes are node 13 and node 1\n",
      "The most similar nodes are node 8 and node 6\n",
      "The most similar nodes are node 16 and node 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "A = randadjmat(20, 0.6)\n",
    "T = transionmat(A)\n",
    "H = hotembd(A)\n",
    "embedding_randm = randwalkembd(A, T, H, 10, 4)\n",
    "embedding_hop_1 = hopeneighbormbd(A, H, 1)\n",
    "embedding_hop_2 = hopeneighbormbd(A, H, 2)\n",
    "\n",
    "similarnodes(embedding_randm)\n",
    "similarnodes(embedding_hop_1)\n",
    "similarnodes(embedding_hop_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHkpHDHETGnu"
   },
   "source": [
    "Each node embedding representation has a common purpose; that similar nodes in a graph have similar embeddings. How they differ is how they represent the measure of similarity between nodes. In one-hop and two-hop embeddings, nodes are similar if they share common one-hop or two-hop neighbors. While with random walk, the embeddings include local and distant neighborhood information. Thus, having a different way of measuring similarity, similar nodes with different embedding representation will be different. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assingment 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
